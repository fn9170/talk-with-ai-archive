# é›·è¾¾é•¿å›¾åˆ†å‰²ä¸é‡å æ£€æµ‹æ–¹æ¡ˆ

## ğŸ¯ éœ€æ±‚åˆ†æ

ä½ çš„éœ€æ±‚éå¸¸å…¸å‹ï¼š**8000Ã—640çš„é•¿æ¡é›·è¾¾å›¾ç‰‡** â†’ **640Ã—640çš„æ–¹å½¢å›¾ç‰‡**ï¼Œé¿å…ç›®æ ‡è¢«åˆ†å‰²çº¿åˆ‡æ–­ã€‚

---

## ğŸ§© 1. æ ¸å¿ƒè§£å†³æ–¹æ¡ˆï¼šé‡å åˆ†å‰²æ³•

### ğŸ’¡ **æ ¸å¿ƒæ€æƒ³**
```python
# ä¼ ç»Ÿåˆ†å‰²æ–¹å¼ï¼ˆæœ‰é—®é¢˜ï¼‰
# |---640---|---640---|---640---|...
# é—®é¢˜ï¼šç›®æ ‡å¯èƒ½è¢«åˆ‡æ–­

# é‡å åˆ†å‰²æ–¹å¼ï¼ˆæ¨èï¼‰  
# |---640---|
#      |---640---|
#           |---640---|
# ä¼˜ç‚¹ï¼šæ¯ä¸ªç›®æ ‡è‡³å°‘åœ¨ä¸€ä¸ªå®Œæ•´çª—å£ä¸­
```

### ğŸ“Š **é‡å å‚æ•°è®¾è®¡**
```python
overlap_strategy = {
    "å›¾ç‰‡å°ºå¯¸": "8000 Ã— 640",
    "ç›®æ ‡å°ºå¯¸": "640 Ã— 640", 
    "é‡å æ¯”ä¾‹": "25-50%",           # é‡å 160-320åƒç´ 
    "æ­¥é•¿": "320-480åƒç´ ",          # stride = 640 - overlap
    "åˆ†å‰²æ•°é‡": "çº¦16-25ä¸ªå­å›¾",
    "å†—ä½™åº¦": "æ¯ä¸ªåŒºåŸŸè¢«è¦†ç›–1-2æ¬¡"
}
```

---

## ğŸ’» 2. å®Œæ•´åˆ†å‰²ä»£ç å®ç°

### ğŸ”§ **åŸºç¡€åˆ†å‰²å™¨**
```python
# image_splitter.py - é›·è¾¾å›¾ç‰‡åˆ†å‰²å™¨
import cv2
import numpy as np
import os
from pathlib import Path
import json

class RadarImageSplitter:
    def __init__(self, target_size=640, overlap_ratio=0.25):
        """
        é›·è¾¾å›¾ç‰‡åˆ†å‰²å™¨
        
        Args:
            target_size: ç›®æ ‡åˆ†å‰²å°ºå¯¸ (640)
            overlap_ratio: é‡å æ¯”ä¾‹ (0.25 = 25%)
        """
        self.target_size = target_size
        self.overlap_ratio = overlap_ratio
        self.stride = int(target_size * (1 - overlap_ratio))
        
        print(f"ğŸ¯ åˆ†å‰²å™¨é…ç½®:")
        print(f"   ç›®æ ‡å°ºå¯¸: {target_size}Ã—{target_size}")
        print(f"   é‡å æ¯”ä¾‹: {overlap_ratio*100}%")
        print(f"   æ­¥é•¿: {self.stride}")
    
    def split_single_image(self, image_path, output_dir):
        """
        åˆ†å‰²å•å¼ é•¿å›¾
        """
        # è¯»å–å›¾ç‰‡
        image = cv2.imread(image_path)
        if image is None:
            raise ValueError(f"æ— æ³•è¯»å–å›¾ç‰‡: {image_path}")
        
        height, width = image.shape[:2]
        print(f"ğŸ“ åŸå›¾å°ºå¯¸: {width}Ã—{height}")
        
        # æ£€æŸ¥å°ºå¯¸æ˜¯å¦ç¬¦åˆé¢„æœŸ
        if height != 640:
            print(f"âš ï¸  è­¦å‘Š: å›¾ç‰‡é«˜åº¦ä¸º{height}ï¼Œä¸æ˜¯é¢„æœŸçš„640")
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)
        
        # è·å–åŸå›¾æ–‡ä»¶åï¼ˆä¸å«æ‰©å±•åï¼‰
        base_name = Path(image_path).stem
        
        # åˆ†å‰²ä¿¡æ¯è®°å½•
        split_info = {
            "original_image": image_path,
            "original_size": [width, height],
            "target_size": self.target_size,
            "overlap_ratio": self.overlap_ratio,
            "stride": self.stride,
            "splits": []
        }
        
        split_count = 0
        
        # æ¨ªå‘åˆ†å‰²ï¼ˆxæ–¹å‘ï¼‰
        for x in range(0, width - self.target_size + 1, self.stride):
            # ç¡®ä¿ä¸è¶…å‡ºè¾¹ç•Œ
            if x + self.target_size > width:
                x = width - self.target_size
            
            # çºµå‘å›ºå®šåœ¨ä¸­å¿ƒï¼ˆå¦‚æœé«˜åº¦ä¸å¤Ÿ640ï¼‰
            if height >= self.target_size:
                y = (height - self.target_size) // 2  # å±…ä¸­
            else:
                y = 0  # é¡¶éƒ¨å¯¹é½ï¼Œåç»­éœ€è¦padding
            
            # æå–å­å›¾
            if height >= self.target_size:
                sub_image = image[y:y+self.target_size, x:x+self.target_size]
            else:
                # é«˜åº¦ä¸è¶³æ—¶ï¼Œè¿›è¡Œpadding
                sub_image = image[y:height, x:x+self.target_size]
                # åº•éƒ¨paddingåˆ°640
                padding = self.target_size - height
                sub_image = cv2.copyMakeBorder(
                    sub_image, 0, padding, 0, 0, 
                    cv2.BORDER_CONSTANT, value=[0, 0, 0]
                )
            
            # ä¿å­˜å­å›¾
            split_filename = f"{base_name}_split_{split_count:03d}.jpg"
            split_path = output_path / split_filename
            cv2.imwrite(str(split_path), sub_image)
            
            # è®°å½•åˆ†å‰²ä¿¡æ¯
            split_info["splits"].append({
                "filename": split_filename,
                "position": [x, y],
                "size": [self.target_size, self.target_size]
            })
            
            split_count += 1
            
            # å¦‚æœå·²ç»åˆ°è¾¾å³è¾¹ç•Œï¼Œåœæ­¢
            if x + self.target_size >= width:
                break
        
        print(f"âœ… åˆ†å‰²å®Œæˆ: {split_count} ä¸ªå­å›¾")
        
        # ä¿å­˜åˆ†å‰²ä¿¡æ¯
        info_file = output_path / f"{base_name}_split_info.json"
        with open(info_file, 'w', encoding='utf-8') as f:
            json.dump(split_info, f, indent=2, ensure_ascii=False)
        
        return split_info
    
    def batch_split(self, input_dir, output_dir):
        """
        æ‰¹é‡åˆ†å‰²å›¾ç‰‡
        """
        input_path = Path(input_dir)
        
        # æ”¯æŒçš„å›¾ç‰‡æ ¼å¼
        image_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.tiff']
        
        # è·å–æ‰€æœ‰å›¾ç‰‡æ–‡ä»¶
        image_files = []
        for ext in image_extensions:
            image_files.extend(input_path.glob(f"*{ext}"))
            image_files.extend(input_path.glob(f"*{ext.upper()}"))
        
        print(f"ğŸ“ æ‰¾åˆ° {len(image_files)} å¼ å›¾ç‰‡")
        
        results = []
        for i, image_file in enumerate(image_files):
            print(f"\nğŸ”„ å¤„ç† [{i+1}/{len(image_files)}]: {image_file.name}")
            
            try:
                split_info = self.split_single_image(str(image_file), output_dir)
                results.append(split_info)
            except Exception as e:
                print(f"âŒ å¤„ç†å¤±è´¥: {e}")
                continue
        
        print(f"\nğŸ‰ æ‰¹é‡åˆ†å‰²å®Œæˆ!")
        print(f"   å¤„ç†å›¾ç‰‡: {len(results)}")
        print(f"   ç”Ÿæˆå­å›¾: {sum(len(r['splits']) for r in results)}")
        
        return results

# ä½¿ç”¨ç¤ºä¾‹
def main():
    # åˆ›å»ºåˆ†å‰²å™¨
    splitter = RadarImageSplitter(
        target_size=640,
        overlap_ratio=0.3  # 30%é‡å 
    )
    
    # åˆ†å‰²å•å¼ å›¾ç‰‡
    # splitter.split_single_image("radar_8000x640.jpg", "output/splits/")
    
    # æ‰¹é‡åˆ†å‰²
    splitter.batch_split("input_images/", "output/splits/")

if __name__ == "__main__":
    main()
```

### ğŸ¨ **å¯è§†åŒ–åˆ†å‰²æ•ˆæœ**
```python
# visualize_splits.py - åˆ†å‰²æ•ˆæœå¯è§†åŒ–
import cv2
import json
import matplotlib.pyplot as plt
from pathlib import Path

def visualize_split_regions(image_path, split_info_path):
    """
    å¯è§†åŒ–åˆ†å‰²åŒºåŸŸ
    """
    # è¯»å–åŸå›¾å’Œåˆ†å‰²ä¿¡æ¯
    image = cv2.imread(image_path)
    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    
    with open(split_info_path, 'r', encoding='utf-8') as f:
        split_info = json.load(f)
    
    # åˆ›å»ºå¯è§†åŒ–
    plt.figure(figsize=(20, 8))
    
    # æ˜¾ç¤ºåŸå›¾
    plt.subplot(2, 1, 1)
    plt.imshow(image_rgb)
    plt.title(f"åŸå›¾ ({split_info['original_size'][0]}Ã—{split_info['original_size'][1]})")
    
    # ç»˜åˆ¶åˆ†å‰²åŒºåŸŸ
    for i, split in enumerate(split_info['splits']):
        x, y = split['position']
        size = split['size'][0]  # æ­£æ–¹å½¢
        
        # ç»˜åˆ¶çŸ©å½¢æ¡†
        rect = plt.Rectangle((x, y), size, size, 
                           linewidth=2, edgecolor='red', 
                           facecolor='none', alpha=0.7)
        plt.gca().add_patch(rect)
        
        # æ·»åŠ ç¼–å·
        plt.text(x + 10, y + 30, str(i), 
                color='yellow', fontsize=12, fontweight='bold')
    
    plt.axis('off')
    
    # æ˜¾ç¤ºåˆ†å‰²å­å›¾ç¤ºä¾‹
    plt.subplot(2, 1, 2)
    
    # è¯»å–å‰å‡ ä¸ªå­å›¾å¹¶æ‹¼æ¥æ˜¾ç¤º
    split_dir = Path(split_info_path).parent
    example_count = min(6, len(split_info['splits']))
    
    combined_width = example_count * split_info['target_size']
    combined_image = np.zeros((split_info['target_size'], combined_width, 3), dtype=np.uint8)
    
    for i in range(example_count):
        split_filename = split_info['splits'][i]['filename']
        split_path = split_dir / split_filename
        
        if split_path.exists():
            split_img = cv2.imread(str(split_path))
            split_img_rgb = cv2.cvtColor(split_img, cv2.COLOR_BGR2RGB)
            
            start_x = i * split_info['target_size']
            end_x = (i + 1) * split_info['target_size']
            combined_image[:, start_x:end_x] = split_img_rgb
    
    plt.imshow(combined_image)
    plt.title(f"åˆ†å‰²ç»“æœç¤ºä¾‹ (å‰{example_count}ä¸ª)")
    plt.axis('off')
    
    plt.tight_layout()
    plt.show()
    
    # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
    print(f"ğŸ“Š åˆ†å‰²ç»Ÿè®¡:")
    print(f"   åŸå›¾å°ºå¯¸: {split_info['original_size']}")
    print(f"   åˆ†å‰²å°ºå¯¸: {split_info['target_size']}Ã—{split_info['target_size']}")
    print(f"   é‡å æ¯”ä¾‹: {split_info['overlap_ratio']*100}%")
    print(f"   æ­¥é•¿: {split_info['stride']}")
    print(f"   å­å›¾æ•°é‡: {len(split_info['splits'])}")

# ä½¿ç”¨ç¤ºä¾‹
def main():
    visualize_split_regions(
        "input/radar_8000x640.jpg",
        "output/splits/radar_8000x640_split_info.json"
    )

if __name__ == "__main__":
    main()
```

---

## ğŸ” 3. YOLOæ£€æµ‹ä¸ç»“æœåˆå¹¶

### ğŸ¯ **é‡å æ£€æµ‹æ–¹æ¡ˆ**
```python
# overlap_detector.py - é‡å åŒºåŸŸæ£€æµ‹
from ultralytics import YOLO
import cv2
import json
import numpy as np
from pathlib import Path

class OverlapDetector:
    def __init__(self, model_path, confidence_threshold=0.5):
        """
        é‡å åŒºåŸŸæ£€æµ‹å™¨
        """
        self.model = YOLO(model_path)
        self.conf_threshold = confidence_threshold
        
    def detect_splits(self, split_dir, split_info_path):
        """
        æ£€æµ‹æ‰€æœ‰åˆ†å‰²å­å›¾
        """
        # è¯»å–åˆ†å‰²ä¿¡æ¯
        with open(split_info_path, 'r') as f:
            split_info = json.load(f)
        
        all_detections = []
        
        for i, split in enumerate(split_info['splits']):
            split_filename = split['filename']
            split_path = Path(split_dir) / split_filename
            
            if not split_path.exists():
                continue
            
            # æ£€æµ‹å½“å‰å­å›¾
            results = self.model(str(split_path), conf=self.conf_threshold)
            
            # è½¬æ¢åæ ‡åˆ°åŸå›¾åæ ‡ç³»
            split_detections = self._convert_to_original_coords(
                results[0], split['position'], i
            )
            
            all_detections.extend(split_detections)
            
            print(f"Split {i}: æ£€æµ‹åˆ° {len(split_detections)} ä¸ªç›®æ ‡")
        
        print(f"æ€»æ£€æµ‹ç»“æœ: {len(all_detections)} ä¸ªç›®æ ‡")
        return all_detections
    
    def _convert_to_original_coords(self, result, split_position, split_id):
        """
        å°†å­å›¾åæ ‡è½¬æ¢ä¸ºåŸå›¾åæ ‡
        """
        detections = []
        offset_x, offset_y = split_position
        
        if result.boxes is not None:
            for box in result.boxes:
                # å­å›¾ä¸­çš„åæ ‡
                x1, y1, x2, y2 = box.xyxy[0].tolist()
                
                # è½¬æ¢åˆ°åŸå›¾åæ ‡
                orig_x1 = x1 + offset_x
                orig_y1 = y1 + offset_y
                orig_x2 = x2 + offset_x
                orig_y2 = y2 + offset_y
                
                detection = {
                    'split_id': split_id,
                    'class_id': int(box.cls[0]),
                    'class_name': self.model.names[int(box.cls[0])],
                    'confidence': float(box.conf[0]),
                    'bbox': [orig_x1, orig_y1, orig_x2, orig_y2],
                    'center': [(orig_x1 + orig_x2) / 2, (orig_y1 + orig_y2) / 2],
                    'area': (orig_x2 - orig_x1) * (orig_y2 - orig_y1)
                }
                
                detections.append(detection)
        
        return detections
    
    def merge_overlapping_detections(self, detections, iou_threshold=0.5):
        """
        åˆå¹¶é‡å æ£€æµ‹ç»“æœï¼ˆNMSï¼‰
        """
        if not detections:
            return []
        
        # æŒ‰ç½®ä¿¡åº¦æ’åº
        detections = sorted(detections, key=lambda x: x['confidence'], reverse=True)
        
        merged = []
        used = set()
        
        for i, det in enumerate(detections):
            if i in used:
                continue
            
            # æ‰¾åˆ°ä¸å½“å‰æ£€æµ‹é‡å çš„æ‰€æœ‰æ£€æµ‹
            overlapping = [det]
            
            for j, other_det in enumerate(detections[i+1:], i+1):
                if j in used:
                    continue
                
                # è®¡ç®—IoU
                iou = self._calculate_iou(det['bbox'], other_det['bbox'])
                
                if iou > iou_threshold:
                    overlapping.append(other_det)
                    used.add(j)
            
            # åˆå¹¶é‡å æ£€æµ‹ï¼ˆä½¿ç”¨ç½®ä¿¡åº¦æœ€é«˜çš„ï¼‰
            best_detection = overlapping[0]  # å·²æŒ‰ç½®ä¿¡åº¦æ’åº
            
            # å¯é€‰ï¼šå¹³å‡åæ ‡ï¼ˆå¦‚æœæœ‰å¤šä¸ªé«˜ç½®ä¿¡åº¦æ£€æµ‹ï¼‰
            if len(overlapping) > 1:
                high_conf_detections = [d for d in overlapping if d['confidence'] > 0.7]
                if len(high_conf_detections) > 1:
                    best_detection = self._average_detections(high_conf_detections)
            
            merged.append(best_detection)
            used.add(i)
        
        print(f"ğŸ”„ æ£€æµ‹åˆå¹¶: {len(detections)} â†’ {len(merged)}")
        return merged
    
    def _calculate_iou(self, bbox1, bbox2):
        """
        è®¡ç®—ä¸¤ä¸ªè¾¹ç•Œæ¡†çš„IoU
        """
        x1 = max(bbox1[0], bbox2[0])
        y1 = max(bbox1[1], bbox2[1])
        x2 = min(bbox1[2], bbox2[2])
        y2 = min(bbox1[3], bbox2[3])
        
        if x2 <= x1 or y2 <= y1:
            return 0.0
        
        intersection = (x2 - x1) * (y2 - y1)
        
        area1 = (bbox1[2] - bbox1[0]) * (bbox1[3] - bbox1[1])
        area2 = (bbox2[2] - bbox2[0]) * (bbox2[3] - bbox2[1])
        
        union = area1 + area2 - intersection
        
        return intersection / union if union > 0 else 0.0
    
    def _average_detections(self, detections):
        """
        å¹³å‡å¤šä¸ªæ£€æµ‹ç»“æœ
        """
        # ä½¿ç”¨ç½®ä¿¡åº¦åŠ æƒå¹³å‡
        total_conf = sum(d['confidence'] for d in detections)
        
        avg_bbox = [0, 0, 0, 0]
        for d in detections:
            weight = d['confidence'] / total_conf
            for i in range(4):
                avg_bbox[i] += d['bbox'][i] * weight
        
        # è¿”å›ç½®ä¿¡åº¦æœ€é«˜çš„æ£€æµ‹ï¼Œä½†ä½¿ç”¨å¹³å‡åæ ‡
        best = max(detections, key=lambda x: x['confidence'])
        best['bbox'] = avg_bbox
        best['center'] = [(avg_bbox[0] + avg_bbox[2]) / 2, 
                         (avg_bbox[1] + avg_bbox[3]) / 2]
        
        return best

# ä½¿ç”¨ç¤ºä¾‹
def main():
    # åˆ›å»ºæ£€æµ‹å™¨
    detector = OverlapDetector('best.pt', confidence_threshold=0.5)
    
    # æ£€æµ‹åˆ†å‰²å›¾ç‰‡
    detections = detector.detect_splits(
        'output/splits/',
        'output/splits/radar_8000x640_split_info.json'
    )
    
    # åˆå¹¶é‡å æ£€æµ‹
    merged_detections = detector.merge_overlapping_detections(
        detections, iou_threshold=0.5
    )
    
    # ä¿å­˜ç»“æœ
    with open('final_detections.json', 'w', encoding='utf-8') as f:
        json.dump(merged_detections, f, indent=2, ensure_ascii=False)
    
    print(f"âœ… æœ€ç»ˆæ£€æµ‹ç»“æœ: {len(merged_detections)} ä¸ªç›®æ ‡")

if __name__ == "__main__":
    main()
```

---

## ğŸ¨ 4. ç»“æœå¯è§†åŒ–

### ğŸ“Š **å®Œæ•´ç»“æœå±•ç¤º**
```python
# visualize_results.py - ç»“æœå¯è§†åŒ–
import cv2
import json
import matplotlib.pyplot as plt
import numpy as np

def visualize_final_results(image_path, detections_path, output_path=None):
    """
    å¯è§†åŒ–æœ€ç»ˆæ£€æµ‹ç»“æœ
    """
    # è¯»å–åŸå›¾å’Œæ£€æµ‹ç»“æœ
    image = cv2.imread(image_path)
    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    
    with open(detections_path, 'r', encoding='utf-8') as f:
        detections = json.load(f)
    
    # åˆ›å»ºç»“æœå›¾
    result_image = image_rgb.copy()
    
    # é¢œè‰²åˆ—è¡¨ï¼ˆä¸åŒç±»åˆ«ç”¨ä¸åŒé¢œè‰²ï¼‰
    colors = [
        (255, 0, 0), (0, 255, 0), (0, 0, 255), (255, 255, 0),
        (255, 0, 255), (0, 255, 255), (128, 0, 128), (255, 165, 0)
    ]
    
    # ç»˜åˆ¶æ£€æµ‹æ¡†
    for i, det in enumerate(detections):
        bbox = det['bbox']
        class_name = det['class_name']
        confidence = det['confidence']
        
        # åæ ‡è½¬æ¢
        x1, y1, x2, y2 = map(int, bbox)
        
        # é€‰æ‹©é¢œè‰²
        color = colors[det['class_id'] % len(colors)]
        
        # ç»˜åˆ¶è¾¹ç•Œæ¡†
        cv2.rectangle(result_image, (x1, y1), (x2, y2), color, 2)
        
        # ç»˜åˆ¶æ ‡ç­¾
        label = f"{class_name}: {confidence:.2f}"
        label_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)[0]
        
        # æ ‡ç­¾èƒŒæ™¯
        cv2.rectangle(result_image, 
                     (x1, y1 - label_size[1] - 10),
                     (x1 + label_size[0], y1),
                     color, -1)
        
        # æ ‡ç­¾æ–‡å­—
        cv2.putText(result_image, label, (x1, y1 - 5),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
    
    # æ˜¾ç¤ºç»“æœ
    plt.figure(figsize=(20, 8))
    
    plt.subplot(2, 1, 1)
    plt.imshow(image_rgb)
    plt.title("åŸå§‹é›·è¾¾å›¾åƒ")
    plt.axis('off')
    
    plt.subplot(2, 1, 2)
    plt.imshow(result_image)
    plt.title(f"æ£€æµ‹ç»“æœ (å…±{len(detections)}ä¸ªç›®æ ‡)")
    plt.axis('off')
    
    plt.tight_layout()
    
    # ä¿å­˜ç»“æœ
    if output_path:
        result_bgr = cv2.cvtColor(result_image, cv2.COLOR_RGB2BGR)
        cv2.imwrite(output_path, result_bgr)
        print(f"ğŸ’¾ ç»“æœä¿å­˜åˆ°: {output_path}")
    
    plt.show()
    
    # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
    print(f"\nğŸ“Š æ£€æµ‹ç»Ÿè®¡:")
    print(f"   æ€»ç›®æ ‡æ•°: {len(detections)}")
    
    # æŒ‰ç±»åˆ«ç»Ÿè®¡
    class_counts = {}
    for det in detections:
        class_name = det['class_name']
        class_counts[class_name] = class_counts.get(class_name, 0) + 1
    
    print(f"   ç±»åˆ«åˆ†å¸ƒ:")
    for class_name, count in class_counts.items():
        print(f"     {class_name}: {count}")

# ä½¿ç”¨ç¤ºä¾‹
def main():
    visualize_final_results(
        "input/radar_8000x640.jpg",
        "final_detections.json",
        "output/final_result.jpg"
    )

if __name__ == "__main__":
    main()
```

---

## ğŸš€ 5. å®Œæ•´å·¥ä½œæµç¨‹

### ğŸ“‹ **ä¸€é”®æ‰§è¡Œè„šæœ¬**
```python
# radar_detection_pipeline.py - å®Œæ•´æ£€æµ‹æµæ°´çº¿
import argparse
import os
from pathlib import Path

def run_radar_detection_pipeline(input_image, model_path, output_dir):
    """
    å®Œæ•´çš„é›·è¾¾å›¾åƒæ£€æµ‹æµæ°´çº¿
    """
    print("ğŸš€ å¯åŠ¨é›·è¾¾å›¾åƒæ£€æµ‹æµæ°´çº¿")
    print("=" * 50)
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)
    
    splits_dir = output_path / "splits"
    results_dir = output_path / "results"
    
    # æ­¥éª¤1: å›¾åƒåˆ†å‰²
    print("\nğŸ“ æ­¥éª¤1: å›¾åƒåˆ†å‰²")
    from image_splitter import RadarImageSplitter
    
    splitter = RadarImageSplitter(target_size=640, overlap_ratio=0.3)
    split_info = splitter.split_single_image(input_image, str(splits_dir))
    
    # æ­¥éª¤2: é‡å æ£€æµ‹
    print("\nğŸ” æ­¥éª¤2: ç›®æ ‡æ£€æµ‹")
    from overlap_detector import OverlapDetector
    
    detector = OverlapDetector(model_path, confidence_threshold=0.5)
    
    # æ£€æµ‹åˆ†å‰²å›¾ç‰‡
    split_info_path = splits_dir / f"{Path(input_image).stem}_split_info.json"
    detections = detector.detect_splits(str(splits_dir), str(split_info_path))
    
    # åˆå¹¶é‡å æ£€æµ‹
    merged_detections = detector.merge_overlapping_detections(
        detections, iou_threshold=0.5
    )
    
    # æ­¥éª¤3: ä¿å­˜å’Œå¯è§†åŒ–ç»“æœ
    print("\nğŸ¨ æ­¥éª¤3: ç»“æœä¿å­˜å’Œå¯è§†åŒ–")
    results_dir.mkdir(exist_ok=True)
    
    # ä¿å­˜æ£€æµ‹ç»“æœ
    results_file = results_dir / "detections.json"
    with open(results_file, 'w', encoding='utf-8') as f:
        import json
        json.dump(merged_detections, f, indent=2, ensure_ascii=False)
    
    # å¯è§†åŒ–ç»“æœ
    from visualize_results import visualize_final_results
    
    result_image_path = results_dir / "result_visualization.jpg"
    visualize_final_results(
        input_image, 
        str(results_file), 
        str(result_image_path)
    )
    
    print(f"\nâœ… æ£€æµ‹å®Œæˆ!")
    print(f"   æ£€æµ‹ç›®æ ‡: {len(merged_detections)} ä¸ª")
    print(f"   ç»“æœä¿å­˜: {results_dir}")
    
    return merged_detections

def main():
    parser = argparse.ArgumentParser(description="é›·è¾¾å›¾åƒæ£€æµ‹æµæ°´çº¿")
    parser.add_argument("--input", required=True, help="è¾“å…¥é›·è¾¾å›¾åƒè·¯å¾„")
    parser.add_argument("--model", required=True, help="YOLOæ¨¡å‹è·¯å¾„")
    parser.add_argument("--output", required=True, help="è¾“å‡ºç›®å½•")
    
    args = parser.parse_args()
    
    # è¿è¡Œæ£€æµ‹æµæ°´çº¿
    detections = run_radar_detection_pipeline(
        args.input, args.model, args.output
    )

if __name__ == "__main__":
    # ç›´æ¥è¿è¡Œç¤ºä¾‹
    detections = run_radar_detection_pipeline(
        "input/radar_8000x640.jpg",
        "models/radar_detector.pt", 
        "output/"
    )
```

---

## ğŸ“Š 6. å‚æ•°ä¼˜åŒ–å»ºè®®

### ğŸ¯ **é‡å å‚æ•°é€‰æ‹©**
```python
overlap_recommendations = {
    "å°ç›®æ ‡(< 50px)": {
        "é‡å æ¯”ä¾‹": "50%",
        "åŸå› ": "å°ç›®æ ‡å®¹æ˜“è¢«åˆ‡æ–­ï¼Œéœ€è¦æ›´å¤šé‡å "
    },
    
    "ä¸­ç­‰ç›®æ ‡(50-150px)": {
        "é‡å æ¯”ä¾‹": "30%", 
        "åŸå› ": "å¹³è¡¡æ£€æµ‹æ•ˆæœå’Œè®¡ç®—æ•ˆç‡"
    },
    
    "å¤§ç›®æ ‡(> 150px)": {
        "é‡å æ¯”ä¾‹": "20%",
        "åŸå› ": "å¤§ç›®æ ‡ä¸å®¹æ˜“è¢«å®Œå…¨åˆ‡æ–­"
    },
    
    "å¯†é›†åˆ†å¸ƒ": {
        "é‡å æ¯”ä¾‹": "40%",
        "åŸå› ": "é¿å…ç›¸é‚»ç›®æ ‡è¢«åˆ†å¼€"
    }
}
```

### âš™ï¸ **æ€§èƒ½ä¼˜åŒ–**
```python
performance_tips = {
    "å†…å­˜ä¼˜åŒ–": [
        "åˆ†æ‰¹å¤„ç†å­å›¾ï¼Œé¿å…å…¨éƒ¨åŠ è½½åˆ°å†…å­˜",
        "åŠæ—¶æ¸…ç†ä¸­é—´ç»“æœ",
        "ä½¿ç”¨è¾ƒå°çš„batch_sizeæ£€æµ‹"
    ],
    
    "é€Ÿåº¦ä¼˜åŒ–": [
        "å¹¶è¡Œå¤„ç†å¤šä¸ªå­å›¾",
        "é¢„å…ˆè¿‡æ»¤æ˜æ˜¾çš„ç©ºç™½åŒºåŸŸ",
        "ä½¿ç”¨GPUåŠ é€Ÿæ£€æµ‹"
    ],
    
    "ç²¾åº¦ä¼˜åŒ–": [
        "æ ¹æ®ç›®æ ‡å¤§å°è°ƒæ•´é‡å æ¯”ä¾‹",
        "ä½¿ç”¨é€‚å½“çš„NMSé˜ˆå€¼",
        "åå¤„ç†è¿‡æ»¤ä½ç½®ä¿¡åº¦æ£€æµ‹"
    ]
}
```

---

## ğŸ¯ æ€»ç»“

### âœ… **æ ¸å¿ƒè¦ç‚¹**
1. **é‡å åˆ†å‰²** - 25-50%é‡å é¿å…ç›®æ ‡è¢«åˆ‡æ–­
2. **åæ ‡è½¬æ¢** - å­å›¾åæ ‡è½¬æ¢ä¸ºåŸå›¾åæ ‡
3. **ç»“æœåˆå¹¶** - ä½¿ç”¨NMSå»é™¤é‡å¤æ£€æµ‹
4. **å‚æ•°è°ƒä¼˜** - æ ¹æ®ç›®æ ‡å¤§å°è°ƒæ•´é‡å æ¯”ä¾‹

### ğŸš€ **ä½¿ç”¨æµç¨‹**
1. è¿è¡Œåˆ†å‰²è„šæœ¬ç”Ÿæˆ640Ã—640å­å›¾
2. YOLOæ£€æµ‹æ‰€æœ‰å­å›¾
3. åæ ‡è½¬æ¢å’Œç»“æœåˆå¹¶
4. å¯è§†åŒ–æœ€ç»ˆç»“æœ

è¿™å¥—æ–¹æ¡ˆå¯ä»¥å®Œç¾è§£å†³ä½ çš„8000Ã—640é›·è¾¾å›¾ç‰‡æ£€æµ‹éœ€æ±‚ï¼Œç¡®ä¿ä¸ä¼šæœ‰ç›®æ ‡è¢«åˆ†å‰²çº¿åˆ‡æ–­ï¼

éœ€è¦æˆ‘è¯¦ç»†è§£é‡Šä»»ä½•éƒ¨åˆ†ï¼Œæˆ–è€…å¸®ä½ è°ƒè¯•å…·ä½“çš„ä»£ç å®ç°å—ï¼Ÿ