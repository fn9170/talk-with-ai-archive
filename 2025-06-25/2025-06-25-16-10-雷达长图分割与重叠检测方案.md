# 雷达长图分割与重叠检测方案

## 🎯 需求分析

你的需求非常典型：**8000×640的长条雷达图片** → **640×640的方形图片**，避免目标被分割线切断。

---

## 🧩 1. 核心解决方案：重叠分割法

### 💡 **核心思想**
```python
# 传统分割方式（有问题）
# |---640---|---640---|---640---|...
# 问题：目标可能被切断

# 重叠分割方式（推荐）  
# |---640---|
#      |---640---|
#           |---640---|
# 优点：每个目标至少在一个完整窗口中
```

### 📊 **重叠参数设计**
```python
overlap_strategy = {
    "图片尺寸": "8000 × 640",
    "目标尺寸": "640 × 640", 
    "重叠比例": "25-50%",           # 重叠160-320像素
    "步长": "320-480像素",          # stride = 640 - overlap
    "分割数量": "约16-25个子图",
    "冗余度": "每个区域被覆盖1-2次"
}
```

---

## 💻 2. 完整分割代码实现

### 🔧 **基础分割器**
```python
# image_splitter.py - 雷达图片分割器
import cv2
import numpy as np
import os
from pathlib import Path
import json

class RadarImageSplitter:
    def __init__(self, target_size=640, overlap_ratio=0.25):
        """
        雷达图片分割器
        
        Args:
            target_size: 目标分割尺寸 (640)
            overlap_ratio: 重叠比例 (0.25 = 25%)
        """
        self.target_size = target_size
        self.overlap_ratio = overlap_ratio
        self.stride = int(target_size * (1 - overlap_ratio))
        
        print(f"🎯 分割器配置:")
        print(f"   目标尺寸: {target_size}×{target_size}")
        print(f"   重叠比例: {overlap_ratio*100}%")
        print(f"   步长: {self.stride}")
    
    def split_single_image(self, image_path, output_dir):
        """
        分割单张长图
        """
        # 读取图片
        image = cv2.imread(image_path)
        if image is None:
            raise ValueError(f"无法读取图片: {image_path}")
        
        height, width = image.shape[:2]
        print(f"📏 原图尺寸: {width}×{height}")
        
        # 检查尺寸是否符合预期
        if height != 640:
            print(f"⚠️  警告: 图片高度为{height}，不是预期的640")
        
        # 创建输出目录
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)
        
        # 获取原图文件名（不含扩展名）
        base_name = Path(image_path).stem
        
        # 分割信息记录
        split_info = {
            "original_image": image_path,
            "original_size": [width, height],
            "target_size": self.target_size,
            "overlap_ratio": self.overlap_ratio,
            "stride": self.stride,
            "splits": []
        }
        
        split_count = 0
        
        # 横向分割（x方向）
        for x in range(0, width - self.target_size + 1, self.stride):
            # 确保不超出边界
            if x + self.target_size > width:
                x = width - self.target_size
            
            # 纵向固定在中心（如果高度不够640）
            if height >= self.target_size:
                y = (height - self.target_size) // 2  # 居中
            else:
                y = 0  # 顶部对齐，后续需要padding
            
            # 提取子图
            if height >= self.target_size:
                sub_image = image[y:y+self.target_size, x:x+self.target_size]
            else:
                # 高度不足时，进行padding
                sub_image = image[y:height, x:x+self.target_size]
                # 底部padding到640
                padding = self.target_size - height
                sub_image = cv2.copyMakeBorder(
                    sub_image, 0, padding, 0, 0, 
                    cv2.BORDER_CONSTANT, value=[0, 0, 0]
                )
            
            # 保存子图
            split_filename = f"{base_name}_split_{split_count:03d}.jpg"
            split_path = output_path / split_filename
            cv2.imwrite(str(split_path), sub_image)
            
            # 记录分割信息
            split_info["splits"].append({
                "filename": split_filename,
                "position": [x, y],
                "size": [self.target_size, self.target_size]
            })
            
            split_count += 1
            
            # 如果已经到达右边界，停止
            if x + self.target_size >= width:
                break
        
        print(f"✅ 分割完成: {split_count} 个子图")
        
        # 保存分割信息
        info_file = output_path / f"{base_name}_split_info.json"
        with open(info_file, 'w', encoding='utf-8') as f:
            json.dump(split_info, f, indent=2, ensure_ascii=False)
        
        return split_info
    
    def batch_split(self, input_dir, output_dir):
        """
        批量分割图片
        """
        input_path = Path(input_dir)
        
        # 支持的图片格式
        image_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.tiff']
        
        # 获取所有图片文件
        image_files = []
        for ext in image_extensions:
            image_files.extend(input_path.glob(f"*{ext}"))
            image_files.extend(input_path.glob(f"*{ext.upper()}"))
        
        print(f"📁 找到 {len(image_files)} 张图片")
        
        results = []
        for i, image_file in enumerate(image_files):
            print(f"\n🔄 处理 [{i+1}/{len(image_files)}]: {image_file.name}")
            
            try:
                split_info = self.split_single_image(str(image_file), output_dir)
                results.append(split_info)
            except Exception as e:
                print(f"❌ 处理失败: {e}")
                continue
        
        print(f"\n🎉 批量分割完成!")
        print(f"   处理图片: {len(results)}")
        print(f"   生成子图: {sum(len(r['splits']) for r in results)}")
        
        return results

# 使用示例
def main():
    # 创建分割器
    splitter = RadarImageSplitter(
        target_size=640,
        overlap_ratio=0.3  # 30%重叠
    )
    
    # 分割单张图片
    # splitter.split_single_image("radar_8000x640.jpg", "output/splits/")
    
    # 批量分割
    splitter.batch_split("input_images/", "output/splits/")

if __name__ == "__main__":
    main()
```

### 🎨 **可视化分割效果**
```python
# visualize_splits.py - 分割效果可视化
import cv2
import json
import matplotlib.pyplot as plt
from pathlib import Path

def visualize_split_regions(image_path, split_info_path):
    """
    可视化分割区域
    """
    # 读取原图和分割信息
    image = cv2.imread(image_path)
    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    
    with open(split_info_path, 'r', encoding='utf-8') as f:
        split_info = json.load(f)
    
    # 创建可视化
    plt.figure(figsize=(20, 8))
    
    # 显示原图
    plt.subplot(2, 1, 1)
    plt.imshow(image_rgb)
    plt.title(f"原图 ({split_info['original_size'][0]}×{split_info['original_size'][1]})")
    
    # 绘制分割区域
    for i, split in enumerate(split_info['splits']):
        x, y = split['position']
        size = split['size'][0]  # 正方形
        
        # 绘制矩形框
        rect = plt.Rectangle((x, y), size, size, 
                           linewidth=2, edgecolor='red', 
                           facecolor='none', alpha=0.7)
        plt.gca().add_patch(rect)
        
        # 添加编号
        plt.text(x + 10, y + 30, str(i), 
                color='yellow', fontsize=12, fontweight='bold')
    
    plt.axis('off')
    
    # 显示分割子图示例
    plt.subplot(2, 1, 2)
    
    # 读取前几个子图并拼接显示
    split_dir = Path(split_info_path).parent
    example_count = min(6, len(split_info['splits']))
    
    combined_width = example_count * split_info['target_size']
    combined_image = np.zeros((split_info['target_size'], combined_width, 3), dtype=np.uint8)
    
    for i in range(example_count):
        split_filename = split_info['splits'][i]['filename']
        split_path = split_dir / split_filename
        
        if split_path.exists():
            split_img = cv2.imread(str(split_path))
            split_img_rgb = cv2.cvtColor(split_img, cv2.COLOR_BGR2RGB)
            
            start_x = i * split_info['target_size']
            end_x = (i + 1) * split_info['target_size']
            combined_image[:, start_x:end_x] = split_img_rgb
    
    plt.imshow(combined_image)
    plt.title(f"分割结果示例 (前{example_count}个)")
    plt.axis('off')
    
    plt.tight_layout()
    plt.show()
    
    # 打印统计信息
    print(f"📊 分割统计:")
    print(f"   原图尺寸: {split_info['original_size']}")
    print(f"   分割尺寸: {split_info['target_size']}×{split_info['target_size']}")
    print(f"   重叠比例: {split_info['overlap_ratio']*100}%")
    print(f"   步长: {split_info['stride']}")
    print(f"   子图数量: {len(split_info['splits'])}")

# 使用示例
def main():
    visualize_split_regions(
        "input/radar_8000x640.jpg",
        "output/splits/radar_8000x640_split_info.json"
    )

if __name__ == "__main__":
    main()
```

---

## 🔍 3. YOLO检测与结果合并

### 🎯 **重叠检测方案**
```python
# overlap_detector.py - 重叠区域检测
from ultralytics import YOLO
import cv2
import json
import numpy as np
from pathlib import Path

class OverlapDetector:
    def __init__(self, model_path, confidence_threshold=0.5):
        """
        重叠区域检测器
        """
        self.model = YOLO(model_path)
        self.conf_threshold = confidence_threshold
        
    def detect_splits(self, split_dir, split_info_path):
        """
        检测所有分割子图
        """
        # 读取分割信息
        with open(split_info_path, 'r') as f:
            split_info = json.load(f)
        
        all_detections = []
        
        for i, split in enumerate(split_info['splits']):
            split_filename = split['filename']
            split_path = Path(split_dir) / split_filename
            
            if not split_path.exists():
                continue
            
            # 检测当前子图
            results = self.model(str(split_path), conf=self.conf_threshold)
            
            # 转换坐标到原图坐标系
            split_detections = self._convert_to_original_coords(
                results[0], split['position'], i
            )
            
            all_detections.extend(split_detections)
            
            print(f"Split {i}: 检测到 {len(split_detections)} 个目标")
        
        print(f"总检测结果: {len(all_detections)} 个目标")
        return all_detections
    
    def _convert_to_original_coords(self, result, split_position, split_id):
        """
        将子图坐标转换为原图坐标
        """
        detections = []
        offset_x, offset_y = split_position
        
        if result.boxes is not None:
            for box in result.boxes:
                # 子图中的坐标
                x1, y1, x2, y2 = box.xyxy[0].tolist()
                
                # 转换到原图坐标
                orig_x1 = x1 + offset_x
                orig_y1 = y1 + offset_y
                orig_x2 = x2 + offset_x
                orig_y2 = y2 + offset_y
                
                detection = {
                    'split_id': split_id,
                    'class_id': int(box.cls[0]),
                    'class_name': self.model.names[int(box.cls[0])],
                    'confidence': float(box.conf[0]),
                    'bbox': [orig_x1, orig_y1, orig_x2, orig_y2],
                    'center': [(orig_x1 + orig_x2) / 2, (orig_y1 + orig_y2) / 2],
                    'area': (orig_x2 - orig_x1) * (orig_y2 - orig_y1)
                }
                
                detections.append(detection)
        
        return detections
    
    def merge_overlapping_detections(self, detections, iou_threshold=0.5):
        """
        合并重叠检测结果（NMS）
        """
        if not detections:
            return []
        
        # 按置信度排序
        detections = sorted(detections, key=lambda x: x['confidence'], reverse=True)
        
        merged = []
        used = set()
        
        for i, det in enumerate(detections):
            if i in used:
                continue
            
            # 找到与当前检测重叠的所有检测
            overlapping = [det]
            
            for j, other_det in enumerate(detections[i+1:], i+1):
                if j in used:
                    continue
                
                # 计算IoU
                iou = self._calculate_iou(det['bbox'], other_det['bbox'])
                
                if iou > iou_threshold:
                    overlapping.append(other_det)
                    used.add(j)
            
            # 合并重叠检测（使用置信度最高的）
            best_detection = overlapping[0]  # 已按置信度排序
            
            # 可选：平均坐标（如果有多个高置信度检测）
            if len(overlapping) > 1:
                high_conf_detections = [d for d in overlapping if d['confidence'] > 0.7]
                if len(high_conf_detections) > 1:
                    best_detection = self._average_detections(high_conf_detections)
            
            merged.append(best_detection)
            used.add(i)
        
        print(f"🔄 检测合并: {len(detections)} → {len(merged)}")
        return merged
    
    def _calculate_iou(self, bbox1, bbox2):
        """
        计算两个边界框的IoU
        """
        x1 = max(bbox1[0], bbox2[0])
        y1 = max(bbox1[1], bbox2[1])
        x2 = min(bbox1[2], bbox2[2])
        y2 = min(bbox1[3], bbox2[3])
        
        if x2 <= x1 or y2 <= y1:
            return 0.0
        
        intersection = (x2 - x1) * (y2 - y1)
        
        area1 = (bbox1[2] - bbox1[0]) * (bbox1[3] - bbox1[1])
        area2 = (bbox2[2] - bbox2[0]) * (bbox2[3] - bbox2[1])
        
        union = area1 + area2 - intersection
        
        return intersection / union if union > 0 else 0.0
    
    def _average_detections(self, detections):
        """
        平均多个检测结果
        """
        # 使用置信度加权平均
        total_conf = sum(d['confidence'] for d in detections)
        
        avg_bbox = [0, 0, 0, 0]
        for d in detections:
            weight = d['confidence'] / total_conf
            for i in range(4):
                avg_bbox[i] += d['bbox'][i] * weight
        
        # 返回置信度最高的检测，但使用平均坐标
        best = max(detections, key=lambda x: x['confidence'])
        best['bbox'] = avg_bbox
        best['center'] = [(avg_bbox[0] + avg_bbox[2]) / 2, 
                         (avg_bbox[1] + avg_bbox[3]) / 2]
        
        return best

# 使用示例
def main():
    # 创建检测器
    detector = OverlapDetector('best.pt', confidence_threshold=0.5)
    
    # 检测分割图片
    detections = detector.detect_splits(
        'output/splits/',
        'output/splits/radar_8000x640_split_info.json'
    )
    
    # 合并重叠检测
    merged_detections = detector.merge_overlapping_detections(
        detections, iou_threshold=0.5
    )
    
    # 保存结果
    with open('final_detections.json', 'w', encoding='utf-8') as f:
        json.dump(merged_detections, f, indent=2, ensure_ascii=False)
    
    print(f"✅ 最终检测结果: {len(merged_detections)} 个目标")

if __name__ == "__main__":
    main()
```

---

## 🎨 4. 结果可视化

### 📊 **完整结果展示**
```python
# visualize_results.py - 结果可视化
import cv2
import json
import matplotlib.pyplot as plt
import numpy as np

def visualize_final_results(image_path, detections_path, output_path=None):
    """
    可视化最终检测结果
    """
    # 读取原图和检测结果
    image = cv2.imread(image_path)
    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    
    with open(detections_path, 'r', encoding='utf-8') as f:
        detections = json.load(f)
    
    # 创建结果图
    result_image = image_rgb.copy()
    
    # 颜色列表（不同类别用不同颜色）
    colors = [
        (255, 0, 0), (0, 255, 0), (0, 0, 255), (255, 255, 0),
        (255, 0, 255), (0, 255, 255), (128, 0, 128), (255, 165, 0)
    ]
    
    # 绘制检测框
    for i, det in enumerate(detections):
        bbox = det['bbox']
        class_name = det['class_name']
        confidence = det['confidence']
        
        # 坐标转换
        x1, y1, x2, y2 = map(int, bbox)
        
        # 选择颜色
        color = colors[det['class_id'] % len(colors)]
        
        # 绘制边界框
        cv2.rectangle(result_image, (x1, y1), (x2, y2), color, 2)
        
        # 绘制标签
        label = f"{class_name}: {confidence:.2f}"
        label_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)[0]
        
        # 标签背景
        cv2.rectangle(result_image, 
                     (x1, y1 - label_size[1] - 10),
                     (x1 + label_size[0], y1),
                     color, -1)
        
        # 标签文字
        cv2.putText(result_image, label, (x1, y1 - 5),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
    
    # 显示结果
    plt.figure(figsize=(20, 8))
    
    plt.subplot(2, 1, 1)
    plt.imshow(image_rgb)
    plt.title("原始雷达图像")
    plt.axis('off')
    
    plt.subplot(2, 1, 2)
    plt.imshow(result_image)
    plt.title(f"检测结果 (共{len(detections)}个目标)")
    plt.axis('off')
    
    plt.tight_layout()
    
    # 保存结果
    if output_path:
        result_bgr = cv2.cvtColor(result_image, cv2.COLOR_RGB2BGR)
        cv2.imwrite(output_path, result_bgr)
        print(f"💾 结果保存到: {output_path}")
    
    plt.show()
    
    # 打印统计信息
    print(f"\n📊 检测统计:")
    print(f"   总目标数: {len(detections)}")
    
    # 按类别统计
    class_counts = {}
    for det in detections:
        class_name = det['class_name']
        class_counts[class_name] = class_counts.get(class_name, 0) + 1
    
    print(f"   类别分布:")
    for class_name, count in class_counts.items():
        print(f"     {class_name}: {count}")

# 使用示例
def main():
    visualize_final_results(
        "input/radar_8000x640.jpg",
        "final_detections.json",
        "output/final_result.jpg"
    )

if __name__ == "__main__":
    main()
```

---

## 🚀 5. 完整工作流程

### 📋 **一键执行脚本**
```python
# radar_detection_pipeline.py - 完整检测流水线
import argparse
import os
from pathlib import Path

def run_radar_detection_pipeline(input_image, model_path, output_dir):
    """
    完整的雷达图像检测流水线
    """
    print("🚀 启动雷达图像检测流水线")
    print("=" * 50)
    
    # 创建输出目录
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)
    
    splits_dir = output_path / "splits"
    results_dir = output_path / "results"
    
    # 步骤1: 图像分割
    print("\n📝 步骤1: 图像分割")
    from image_splitter import RadarImageSplitter
    
    splitter = RadarImageSplitter(target_size=640, overlap_ratio=0.3)
    split_info = splitter.split_single_image(input_image, str(splits_dir))
    
    # 步骤2: 重叠检测
    print("\n🔍 步骤2: 目标检测")
    from overlap_detector import OverlapDetector
    
    detector = OverlapDetector(model_path, confidence_threshold=0.5)
    
    # 检测分割图片
    split_info_path = splits_dir / f"{Path(input_image).stem}_split_info.json"
    detections = detector.detect_splits(str(splits_dir), str(split_info_path))
    
    # 合并重叠检测
    merged_detections = detector.merge_overlapping_detections(
        detections, iou_threshold=0.5
    )
    
    # 步骤3: 保存和可视化结果
    print("\n🎨 步骤3: 结果保存和可视化")
    results_dir.mkdir(exist_ok=True)
    
    # 保存检测结果
    results_file = results_dir / "detections.json"
    with open(results_file, 'w', encoding='utf-8') as f:
        import json
        json.dump(merged_detections, f, indent=2, ensure_ascii=False)
    
    # 可视化结果
    from visualize_results import visualize_final_results
    
    result_image_path = results_dir / "result_visualization.jpg"
    visualize_final_results(
        input_image, 
        str(results_file), 
        str(result_image_path)
    )
    
    print(f"\n✅ 检测完成!")
    print(f"   检测目标: {len(merged_detections)} 个")
    print(f"   结果保存: {results_dir}")
    
    return merged_detections

def main():
    parser = argparse.ArgumentParser(description="雷达图像检测流水线")
    parser.add_argument("--input", required=True, help="输入雷达图像路径")
    parser.add_argument("--model", required=True, help="YOLO模型路径")
    parser.add_argument("--output", required=True, help="输出目录")
    
    args = parser.parse_args()
    
    # 运行检测流水线
    detections = run_radar_detection_pipeline(
        args.input, args.model, args.output
    )

if __name__ == "__main__":
    # 直接运行示例
    detections = run_radar_detection_pipeline(
        "input/radar_8000x640.jpg",
        "models/radar_detector.pt", 
        "output/"
    )
```

---

## 📊 6. 参数优化建议

### 🎯 **重叠参数选择**
```python
overlap_recommendations = {
    "小目标(< 50px)": {
        "重叠比例": "50%",
        "原因": "小目标容易被切断，需要更多重叠"
    },
    
    "中等目标(50-150px)": {
        "重叠比例": "30%", 
        "原因": "平衡检测效果和计算效率"
    },
    
    "大目标(> 150px)": {
        "重叠比例": "20%",
        "原因": "大目标不容易被完全切断"
    },
    
    "密集分布": {
        "重叠比例": "40%",
        "原因": "避免相邻目标被分开"
    }
}
```

### ⚙️ **性能优化**
```python
performance_tips = {
    "内存优化": [
        "分批处理子图，避免全部加载到内存",
        "及时清理中间结果",
        "使用较小的batch_size检测"
    ],
    
    "速度优化": [
        "并行处理多个子图",
        "预先过滤明显的空白区域",
        "使用GPU加速检测"
    ],
    
    "精度优化": [
        "根据目标大小调整重叠比例",
        "使用适当的NMS阈值",
        "后处理过滤低置信度检测"
    ]
}
```

---

## 🎯 总结

### ✅ **核心要点**
1. **重叠分割** - 25-50%重叠避免目标被切断
2. **坐标转换** - 子图坐标转换为原图坐标
3. **结果合并** - 使用NMS去除重复检测
4. **参数调优** - 根据目标大小调整重叠比例

### 🚀 **使用流程**
1. 运行分割脚本生成640×640子图
2. YOLO检测所有子图
3. 坐标转换和结果合并
4. 可视化最终结果

这套方案可以完美解决你的8000×640雷达图片检测需求，确保不会有目标被分割线切断！

需要我详细解释任何部分，或者帮你调试具体的代码实现吗？